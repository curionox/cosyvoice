#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆ CosyVoice FastAPI æœåŠ¡å™¨å¯åŠ¨è„šæœ¬
è‡ªåŠ¨åº”ç”¨æœ€ä½³æ€§èƒ½é…ç½®
"""
import sys
import os
import argparse
import subprocess
import time

def check_gpu_memory():
    """æ£€æŸ¥GPUå†…å­˜"""
    try:
        import torch
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name(0)}")
            print(f"GPUå†…å­˜: {gpu_memory:.1f}GB")
            return gpu_memory
        else:
            print("æœªæ£€æµ‹åˆ°CUDA GPU")
            return 0
    except:
        print("æ— æ³•æ£€æµ‹GPUä¿¡æ¯")
        return 0

def recommend_config(gpu_memory_gb):
    """æ ¹æ®GPUå†…å­˜æ¨èé…ç½®"""
    if gpu_memory_gb >= 8:
        return {
            'trt_concurrent': 2,
            'fp16': True,
            'load_trt': True,
            'load_jit': True,
            'note': 'é«˜æ€§èƒ½é…ç½® (8GB+ GPU)'
        }
    elif gpu_memory_gb >= 4:
        return {
            'trt_concurrent': 1,
            'fp16': True,
            'load_trt': True,
            'load_jit': True,
            'note': 'æ ‡å‡†é…ç½® (4-8GB GPU)'
        }
    elif gpu_memory_gb >= 2:
        return {
            'trt_concurrent': 1,
            'fp16': True,
            'load_trt': False,
            'load_jit': True,
            'note': 'è½»é‡é…ç½® (2-4GB GPU)'
        }
    else:
        return {
            'trt_concurrent': 1,
            'fp16': False,
            'load_trt': False,
            'load_jit': True,
            'note': 'CPUæˆ–ä½æ˜¾å­˜é…ç½®'
        }

def build_command(model_dir, port, config):
    """æ„å»ºå¯åŠ¨å‘½ä»¤"""
    cmd = [
        sys.executable, 'fastapi_server.py',
        '--model_dir', model_dir,
        '--port', str(port),
        '--trt_concurrent', str(config['trt_concurrent'])
    ]
    
    if config['fp16']:
        cmd.append('--fp16')
    if config['load_trt']:
        cmd.append('--load_trt')
    if config['load_jit']:
        cmd.append('--load_jit')
    
    return cmd

def main():
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆCosyVoiceæœåŠ¡å™¨å¯åŠ¨å™¨')
    parser.add_argument('--model_dir', type=str, 
                        default='pretrained_models/CosyVoice-300M-SFT',
                        help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--port', type=int, default=9234,
                        help='æœåŠ¡ç«¯å£')
    parser.add_argument('--auto_config', action='store_true', default=True,
                        help='è‡ªåŠ¨é…ç½®ä¼˜åŒ–å‚æ•° (é»˜è®¤å¯ç”¨)')
    parser.add_argument('--manual_config', action='store_true',
                        help='æ‰‹åŠ¨é…ç½®å‚æ•°')
    parser.add_argument('--precompile', action='store_true',
                        help='å¯åŠ¨å‰é¢„ç¼–è¯‘TensorRTå¼•æ“')
    parser.add_argument('--benchmark', action='store_true',
                        help='å¯åŠ¨å‰è¿è¡Œæ€§èƒ½æµ‹è¯•')
    
    # æ‰‹åŠ¨é…ç½®é€‰é¡¹
    parser.add_argument('--load_trt', action='store_true',
                        help='å¯ç”¨TensorRT')
    parser.add_argument('--load_jit', action='store_true',
                        help='å¯ç”¨JIT')
    parser.add_argument('--fp16', action='store_true',
                        help='å¯ç”¨FP16')
    parser.add_argument('--trt_concurrent', type=int, default=1,
                        help='TensorRTå¹¶å‘æ•°')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("CosyVoice ä¼˜åŒ–ç‰ˆæœåŠ¡å™¨å¯åŠ¨å™¨")
    print("=" * 60)
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if not os.path.exists(args.model_dir):
        print(f"âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {args.model_dir}")
        return
    
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {args.model_dir}")
    print(f"ğŸŒ æœåŠ¡ç«¯å£: {args.port}")
    
    # ç¡®å®šé…ç½®
    if args.manual_config:
        config = {
            'trt_concurrent': args.trt_concurrent,
            'fp16': args.fp16,
            'load_trt': args.load_trt,
            'load_jit': args.load_jit,
            'note': 'æ‰‹åŠ¨é…ç½®'
        }
    else:
        # è‡ªåŠ¨é…ç½®
        print("\nğŸ” æ£€æµ‹ç¡¬ä»¶é…ç½®...")
        gpu_memory = check_gpu_memory()
        config = recommend_config(gpu_memory)
    
    print(f"\nâš™ï¸  æ¨èé…ç½®: {config['note']}")
    print(f"   - TensorRT: {config['load_trt']}")
    print(f"   - JITç¼–è¯‘: {config['load_jit']}")
    print(f"   - FP16åŠç²¾åº¦: {config['fp16']}")
    print(f"   - TRTå¹¶å‘æ•°: {config['trt_concurrent']}")
    
    # é¢„ç¼–è¯‘TensorRTå¼•æ“
    if args.precompile and config['load_trt']:
        print("\nğŸ”¥ é¢„ç¼–è¯‘TensorRTå¼•æ“...")
        precompile_cmd = [
            sys.executable, 'precompile_trt.py',
            '--model_dir', args.model_dir,
            '--trt_concurrent', str(config['trt_concurrent'])
        ]
        if config['fp16']:
            precompile_cmd.append('--fp16')
        else:
            precompile_cmd.append('--no_fp16')
        
        try:
            subprocess.run(precompile_cmd, check=True)
            print("âœ… TensorRTå¼•æ“é¢„ç¼–è¯‘å®Œæˆ")
        except subprocess.CalledProcessError:
            print("âš ï¸  TensorRTé¢„ç¼–è¯‘å¤±è´¥ï¼Œç»§ç»­å¯åŠ¨æœåŠ¡å™¨")
    
    # æ€§èƒ½æµ‹è¯•
    if args.benchmark:
        print("\nğŸ“Š è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        benchmark_cmd = [
            sys.executable, 'benchmark_performance.py',
            '--model_dir', args.model_dir
        ]
        if config['load_trt']:
            benchmark_cmd.append('--load_trt')
        if config['load_jit']:
            benchmark_cmd.append('--load_jit')
        if config['fp16']:
            benchmark_cmd.append('--fp16')
        
        try:
            subprocess.run(benchmark_cmd, check=True)
        except subprocess.CalledProcessError:
            print("âš ï¸  æ€§èƒ½æµ‹è¯•å¤±è´¥ï¼Œç»§ç»­å¯åŠ¨æœåŠ¡å™¨")
    
    # æ„å»ºå¯åŠ¨å‘½ä»¤
    cmd = build_command(args.model_dir, args.port, config)
    
    print(f"\nğŸš€ å¯åŠ¨æœåŠ¡å™¨...")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print(f"\nğŸ“– æœåŠ¡æ–‡æ¡£: http://localhost:{args.port}/docs")
    print(f"ğŸ¯ APIç«¯ç‚¹: http://localhost:{args.port}/")
    print(f"\nğŸ’¡ ä¼˜åŒ–æç¤º:")
    print(f"   - é•¿æ–‡æœ¬ä¼šè‡ªåŠ¨åˆ†å‰²ä¼˜åŒ–")
    print(f"   - æ”¯æŒæµå¼åˆæˆæå‡å“åº”é€Ÿåº¦")
    print(f"   - å¯è°ƒç”¨ /warmup_trt é¢„çƒ­å¼•æ“")
    print(f"   - æŸ¥çœ‹ /performance_info è·å–é…ç½®ä¿¡æ¯")
    
    print(f"\n{'='*60}")
    print("æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    print(f"{'='*60}")
    
    try:
        subprocess.run(cmd)
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")

if __name__ == '__main__':
    main()
